{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp = pd.read_csv(\"yelp_new.csv\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "      <th>text_nopunct</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_nostopwords</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>Positivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rv-GQvyaeCASy2vYEJjGOA</td>\n",
       "      <td>qVRavGPFSpCarN21vCOHRw</td>\n",
       "      <td>X2frauzhGG3vOmXpcb5cFQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-08-04</td>\n",
       "      <td>I've been to a few movie festivals in Europe, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Festival Fantasia\"</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.575851</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Arts &amp; Entertainment;Cinema</td>\n",
       "      <td>Ive been to a few movie festivals in Europe an...</td>\n",
       "      <td>['ive', 'been', 'to', 'a', 'few', 'movie', 'fe...</td>\n",
       "      <td>['ive', 'movie', 'festivals', 'europe', 'first...</td>\n",
       "      <td>[\"['ive',\", \"'movie',\", \"'festivals',\", \"'euro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5h6IB5PRrENw4nJD0trfjw</td>\n",
       "      <td>TOunAZFMiaKHIoxCqt5XKA</td>\n",
       "      <td>A4zLP5AyKEEHQr_dWEZKig</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-12-27</td>\n",
       "      <td>Excellent food. Excellent service. Excellent a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Cleo\"</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.156616</td>\n",
       "      <td>4.5</td>\n",
       "      <td>459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Greek;Middle Eastern;Restaurants;Mediterranean...</td>\n",
       "      <td>Excellent food Excellent service Excellent amb...</td>\n",
       "      <td>['excellent', 'food', 'excellent', 'service', ...</td>\n",
       "      <td>['excellent', 'food', 'excellent', 'service', ...</td>\n",
       "      <td>[\"['excellent',\", \"'food',\", \"'excellent',\", \"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w14j-zXZm_JaqAS3VP5XzA</td>\n",
       "      <td>bUsNeErcrACybENrGTPb5g</td>\n",
       "      <td>ee8aiHC6zaY9JoLUVUSc1w</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-06-02</td>\n",
       "      <td>Winchell's is always on our list of lunch dest...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Winchell's Pub &amp; Grill\"</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.103376</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bars;Nightlife;American (Traditional);Restaura...</td>\n",
       "      <td>Winchells is always on our list of lunch desti...</td>\n",
       "      <td>['winchells', 'is', 'always', 'on', 'our', 'li...</td>\n",
       "      <td>['winchells', 'always', 'list', 'lunch', 'dest...</td>\n",
       "      <td>[\"['winchells',\", \"'always',\", \"'list',\", \"'lu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-oDFOOAjruW0ZBGsjOVEbQ</td>\n",
       "      <td>46MciGU_hQ3G04CqSBeFxw</td>\n",
       "      <td>u6-m3zvnWn7X162Es8RvPw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>For being your neighborhood Ace Store, they do...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Southern Highlands Ace Hardware\"</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.205466</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Home &amp; Garden;Shopping;Hardware Stores</td>\n",
       "      <td>For being your neighborhood Ace Store they don...</td>\n",
       "      <td>['for', 'being', 'your', 'neighborhood', 'ace'...</td>\n",
       "      <td>['neighborhood', 'ace', 'store', 'dont', 'stoc...</td>\n",
       "      <td>[\"['neighborhood',\", \"'ace',\", \"'store',\", \"'d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imDHZk__p_yxef_PkA2RIQ</td>\n",
       "      <td>qgbbuhfSkH5_Tna5t9tE-A</td>\n",
       "      <td>FaHADZARwnY4yvlvpnsfGA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-11-10</td>\n",
       "      <td>McCarran has huge revenue available to make an...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"McCarran International Airport\"</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.151009</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hotels &amp; Travel;Airports</td>\n",
       "      <td>McCarran has huge revenue available to make an...</td>\n",
       "      <td>['mccarran', 'has', 'huge', 'revenue', 'availa...</td>\n",
       "      <td>['mccarran', 'huge', 'revenue', 'available', '...</td>\n",
       "      <td>[\"['mccarran',\", \"'huge',\", \"'revenue',\", \"'av...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  rv-GQvyaeCASy2vYEJjGOA  qVRavGPFSpCarN21vCOHRw  X2frauzhGG3vOmXpcb5cFQ   \n",
       "1  5h6IB5PRrENw4nJD0trfjw  TOunAZFMiaKHIoxCqt5XKA  A4zLP5AyKEEHQr_dWEZKig   \n",
       "2  w14j-zXZm_JaqAS3VP5XzA  bUsNeErcrACybENrGTPb5g  ee8aiHC6zaY9JoLUVUSc1w   \n",
       "3  -oDFOOAjruW0ZBGsjOVEbQ  46MciGU_hQ3G04CqSBeFxw  u6-m3zvnWn7X162Es8RvPw   \n",
       "4  imDHZk__p_yxef_PkA2RIQ  qgbbuhfSkH5_Tna5t9tE-A  FaHADZARwnY4yvlvpnsfGA   \n",
       "\n",
       "   review_rating        date  \\\n",
       "0            5.0  2014-08-04   \n",
       "1            5.0  2014-12-27   \n",
       "2            5.0  2011-06-02   \n",
       "3            2.0  2014-01-14   \n",
       "4            1.0  2007-11-10   \n",
       "\n",
       "                                                text  useful  funny  cool  \\\n",
       "0  I've been to a few movie festivals in Europe, ...     0.0    0.0   1.0   \n",
       "1  Excellent food. Excellent service. Excellent a...     0.0    0.0   0.0   \n",
       "2  Winchell's is always on our list of lunch dest...     1.0    0.0   0.0   \n",
       "3  For being your neighborhood Ace Store, they do...     0.0    0.0   0.0   \n",
       "4  McCarran has huge revenue available to make an...     1.0    0.0   1.0   \n",
       "\n",
       "                                name     ...       longitude stars  \\\n",
       "0                \"Festival Fantasia\"     ...      -73.575851   5.0   \n",
       "1                             \"Cleo\"     ...     -115.156616   4.5   \n",
       "2           \"Winchell's Pub & Grill\"     ...     -115.103376   4.0   \n",
       "3  \"Southern Highlands Ace Hardware\"     ...     -115.205466   4.0   \n",
       "4   \"McCarran International Airport\"     ...     -115.151009   3.5   \n",
       "\n",
       "  review_count is_open                                         categories  \\\n",
       "0          7.0     1.0                        Arts & Entertainment;Cinema   \n",
       "1        459.0     1.0  Greek;Middle Eastern;Restaurants;Mediterranean...   \n",
       "2         53.0     1.0  Bars;Nightlife;American (Traditional);Restaura...   \n",
       "3         30.0     1.0             Home & Garden;Shopping;Hardware Stores   \n",
       "4       3284.0     1.0                           Hotels & Travel;Airports   \n",
       "\n",
       "                                        text_nopunct  \\\n",
       "0  Ive been to a few movie festivals in Europe an...   \n",
       "1  Excellent food Excellent service Excellent amb...   \n",
       "2  Winchells is always on our list of lunch desti...   \n",
       "3  For being your neighborhood Ace Store they don...   \n",
       "4  McCarran has huge revenue available to make an...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  ['ive', 'been', 'to', 'a', 'few', 'movie', 'fe...   \n",
       "1  ['excellent', 'food', 'excellent', 'service', ...   \n",
       "2  ['winchells', 'is', 'always', 'on', 'our', 'li...   \n",
       "3  ['for', 'being', 'your', 'neighborhood', 'ace'...   \n",
       "4  ['mccarran', 'has', 'huge', 'revenue', 'availa...   \n",
       "\n",
       "                                    text_nostopwords  \\\n",
       "0  ['ive', 'movie', 'festivals', 'europe', 'first...   \n",
       "1  ['excellent', 'food', 'excellent', 'service', ...   \n",
       "2  ['winchells', 'always', 'list', 'lunch', 'dest...   \n",
       "3  ['neighborhood', 'ace', 'store', 'dont', 'stoc...   \n",
       "4  ['mccarran', 'huge', 'revenue', 'available', '...   \n",
       "\n",
       "                                     text_lemmatized  Positivity  \n",
       "0  [\"['ive',\", \"'movie',\", \"'festivals',\", \"'euro...           1  \n",
       "1  [\"['excellent',\", \"'food',\", \"'excellent',\", \"...           1  \n",
       "2  [\"['winchells',\", \"'always',\", \"'list',\", \"'lu...           1  \n",
       "3  [\"['neighborhood',\", \"'ace',\", \"'store',\", \"'d...           0  \n",
       "4  [\"['mccarran',\", \"'huge',\", \"'revenue',\", \"'av...           0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp = df_yelp.dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp['date'] = pd.to_datetime(df_yelp['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp = df_yelp.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test train data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelptest = df_yelp[800000:] #20% of whole dataset\n",
    "df_yelptrain = df_yelp[:800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_yelptrain = df_yelptrain['text_nostopwords']\n",
    "y_yelptrain = df_yelptrain['Positivity']\n",
    "y_yelptrain2 = df_yelptrain['review_rating']\n",
    "X_yelptest = df_yelptest['text_nostopwords']\n",
    "y_yelptest = df_yelptest['Positivity']\n",
    "y_yelptest2 = df_yelptest['review_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_transformer = CountVectorizer().fit(df_yelp['text_nostopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reviewtrain = bow_transformer.transform(df_yelptrain['text_nostopwords'])\n",
    "X_reviewtest = bow_transformer.transform(df_yelptest['text_nostopwords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes to predict rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_reviewtrain, y_yelptrain2)\n",
    "Y_pred = nb_model.predict(X_reviewtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy:\n",
      "0.589505\n"
     ]
    }
   ],
   "source": [
    "#print(confusion_matrix(y_test, predict))\n",
    "print('\\n Accuracy for Naive Bayes to predict rating:')\n",
    "print(accuracy_score(y_yelptest2, Y_pred))\n",
    "#print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes to predict sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy:\n",
      "0.848665\n"
     ]
    }
   ],
   "source": [
    "nb_model.fit(X_reviewtrain, y_yelptrain)\n",
    "Y_pred = nb_model.predict(X_reviewtest)\n",
    "print('\\n Accuracy for Naive Bayes to predict sentiment score:')\n",
    "print(accuracy_score(y_yelptest, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression to predict rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_reviewtrain, y_yelptrain2)\n",
    "Y_pred_lg = lg_model.predict(X_reviewtest)\n",
    "#print(accuracy_score(y_yelptest2, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62659"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\n Accuracy for Logistic Regression to predict rating:')\n",
    "print(accuracy_score(y_yelptest2, Y_pred_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression to predict sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88522\n"
     ]
    }
   ],
   "source": [
    "lg_model.fit(X_reviewtrain, y_yelptrain)\n",
    "Y_pred_lg = lg_model.predict(X_reviewtest)\n",
    "print('\\n Accuracy for Logistic Regression to predict sentiment score:')\n",
    "print(accuracy_score(y_yelptest, Y_pred_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting categories from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref = pd.read_excel(\"Category_List.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref = ref.groupby(ref.Categories)['SubCategories'].agg(lambda col: ', '.join(col))\n",
    "ref = pd.DataFrame(ref)\n",
    "ref=ref.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Reference = {}\n",
    "\n",
    "for i in range(ref.shape[0]):\n",
    "    Reference[ref.iloc[i,0]] = ref.iloc[i,1].split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp['cat_list'] = [i.split(\";\") for i in df_yelp.categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_frequency(cell):\n",
    "    ## create a dic with all the keys in Reference but values are all 0 \n",
    "    newDict = {key: 0 for key in Reference.keys()}\n",
    "    for i in cell:\n",
    "        for j in Reference:\n",
    "            if i in Reference[j]:\n",
    "                ## then if the cat in df shows up in the reference values, the value of new dic plus 1 \n",
    "                newDict[j] = newDict[j] + 1 \n",
    "            else:\n",
    "                continue\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp['cat_freq'] = list(map(cat_frequency, df_yelp.cat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_freq_cat(cell):\n",
    "        return max(cell, key=lambda k: cell[k])\n",
    "\n",
    "df_yelp['cat_max'] = list(map(find_freq_cat,df_yelp.cat_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp.to_csv(\"Yelp_withcategories.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_res = df_yelp[df_yelp['cat_max'] == 'Restaurants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_restest = df_res[int(0.8*df_res.shape[0]):] #20% of whole dataset\n",
    "df_restrain = df_res[:int(0.8*df_res.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_restrain = df_restrain['text_nopunct']\n",
    "y_restrain = df_restrain['Positivity']\n",
    "y_restrain2 = df_restrain['review_rating']\n",
    "X_restest = df_restest['text_nopunct']\n",
    "y_restest = df_restest['Positivity']\n",
    "y_restest2 = df_restest['review_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_transformer_res = CountVectorizer().fit(df_res['text_nopunct'])\n",
    "X_reviewtrain_res = bow_transformer_res.transform(df_restrain['text_nopunct'])\n",
    "X_reviewtest_res = bow_transformer_res.transform(df_restest['text_nopunct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5926286111953748\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes to predict rating\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_reviewtrain_res, y_restrain2)\n",
    "Y_pred_res = nb_model.predict(X_reviewtest_res)\n",
    "print('\\n Accuracy for Naive Bayes to predict rating for restaurants:')\n",
    "print(accuracy_score(y_restest2, Y_pred_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy:\n",
      "0.8604057743437841\n"
     ]
    }
   ],
   "source": [
    "## NaiveBayes to predict sentiment score\n",
    "nb_model.fit(X_reviewtrain_res, y_restrain)\n",
    "Y_pred_res = nb_model.predict(X_reviewtest_res)\n",
    "print('\\n Accuracy for NaiveBayes to predict sentiment score for restaurants:')\n",
    "print(accuracy_score(y_restest, Y_pred_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Logistic Regression to predict rating\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_reviewtrain_res, y_restrain2)\n",
    "Y_pred_reslg = lg_model.predict(X_reviewtest_res)\n",
    "print('\\n Accuracy for Logistic Regression to predict rating for restaurants:')\n",
    "print(accuracy_score(y_restest2, Y_pred_reslg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Logistic Regression to predict sentiment score\n",
    "lg_model.fit(X_reviewtrain_res, y_restrain)\n",
    "Y_pred_reslg = lg_model.predict(X_reviewtest_res)\n",
    "print('\\n Accuracy for Logistic Regression to predict sentiment score for restaurants:')\n",
    "print(accuracy_score(y_restest, Y_pred_reslg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    return list(zip(*[input_list[i:] for i in range(n)]))\n",
    "\n",
    "df_yelp['bigrams'] = df_yelp['text_nopunct'].map(lambda x: find_ngrams(x.split(\" \"), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-49a296f0baff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbigram_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_yelp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_nopunct'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib64/python3.4/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    834\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m         \"\"\"\n\u001b[1;32m--> 836\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    837\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python3.4/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python3.4/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bigram_vect = CountVectorizer(ngram_range = (1,2)).fit(df_yelp['text_nopunct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ntest = df_yelp[int(0.8*df_yelp.shape[0]):] #20% of whole dataset\n",
    "df_ntrain = df_yelp[:int(0.8*df_yelp.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ntrain = df_ntrain['text_nopunct']\n",
    "y_ntrain = df_ntrain['Positivity']\n",
    "y_ntrain2 = df_ntrain['review_rating']\n",
    "X_ntest = df_ntest['text_nopunct']\n",
    "y_ntest = df_ntest['Positivity']\n",
    "y_ntest2 = df_ntest['review_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xn_ntrain = bigram_vect.transform(df_ntrain['text_nopunct'])\n",
    "Xn_ntest = bigram_vect.transform(df_ntest['text_nopunct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601865\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes to predict rating\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(Xn_ntrain, y_ntrain2)\n",
    "Yn_pred = nb_model.predict(Xn_ntest)\n",
    "print('\\n Accuracy for Naive Bayes to predict rating for n-gram model:')\n",
    "print(accuracy_score(y_ntest2, Yn_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87588\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes to predict sentiment\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(Xn_ntrain, y_ntrain)\n",
    "Yn_pred = nb_model.predict(Xn_ntest)\n",
    "print('\\n Accuracy for Naive Bayes to predict sentiment for n-gram model:')\n",
    "print(accuracy_score(y_ntest, Yn_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Logistic Regression to predict rating\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(Xn_ntrain, y_ntrain2)\n",
    "Y_pred_reslg = lg_model.predict(Xn_ntest)\n",
    "print('\\n Accuracy for Logistic Regression to predict rating for n-gram model:')\n",
    "print(accuracy_score(y_ntest2, Yn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Logistic Regression to predict sentiment\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(Xn_ntrain, y_ntrain)\n",
    "Y_pred_reslg = lg_model.predict(Xn_ntest)\n",
    "print('\\n Accuracy for Logistic Regression to predict sentiment for n-gram model:')\n",
    "print(accuracy_score(y_ntest, Yn_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
