{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf  \n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the yelp review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict the review rating based on the comments left by yelp users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "df_yelp = pd.read_csv(\"/home/dagrawal1/Text_Analytics/CleanedYelpData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert target variable to one-hot encoding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = to_categorical(df_yelp['review_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data pre-processing: (experiment with 25,000 data points first)\n",
    "1. set vocabulary size to 50,000\n",
    "2. convert comments to one-hot encoding matrix\n",
    "3. limit each the length of comment up to 200 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df_yelp['text'][:25000])\n",
    "sequences = tokenizer.texts_to_sequences(df_yelp['text'][:25000])\n",
    "data = pad_sequences(sequences, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Sequential()\n",
    "simple_model.add(Embedding(50000, 100, input_length=200))\n",
    "simple_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "simple_model.add(Dense(6, activation='sigmoid'))\n",
    "simple_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "import time\n",
    "from keras import callbacks\n",
    "stime = time.time();\n",
    "Simple_lstm_history = simple_model.fit(data, y_binary[:25000],\n",
    "                       epochs = 3, ##number of epochs (passes through the data)\n",
    "                       batch_size = 128, ##batch size\n",
    "                       validation_split = 0.4, ##fraction of data to be used as validation\n",
    "                       shuffle = True, ##shuffle data after each epoch\n",
    "                        callbacks=[keras.callbacks.ModelCheckpoint(\n",
    "                            filepath='multi_weights_simple.h5',\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=True,\n",
    "                            verbose=1)]\n",
    "                       );\n",
    "etime = time.time();\n",
    "print('Total time: '+str(etime-stime));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[15,8]);\n",
    "plt.plot(Simple_lstm_history.history['acc'],'-ro',linewidth=2,label='LSTM Train');\n",
    "\n",
    "plt.plot(Simple_lstm_history.history['val_acc'],':ro',linewidth=2,label='LSTM Test');\n",
    "\n",
    "plt.xlabel('Epoch');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(df_yelp['text'][1000000:1200000])\n",
    "test_data = pad_sequences(test_sequences, maxlen=200)\n",
    "predicted_classes = lstm_model.predict_classes(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_Y = np.array(df_yelp['review_rating'][1000000:1200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_Y,predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(test_Y,predicted_classes)\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"12345\"],\n",
    "                  columns = [i for i in \"12345\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data pre-processing: (experiment with 1 million data points first)\n",
    "1. set vocabulary size to 80,000\n",
    "2. convert comments to one-hot encoding matrix\n",
    "3. limit each the length of comment up to 300 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create sequence\n",
    "vocabulary_size = 80000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df_yelp['text'][:1000000])\n",
    "sequences = tokenizer.texts_to_sequences(df_yelp['text'][:1000000])\n",
    "data = pad_sequences(sequences, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(80000, 100, input_length=300))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(6, activation='sigmoid'))\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from keras import callbacks\n",
    "stime = time.time();\n",
    "lstm_history = lstm_model.fit(data, y_binary[:1000000],\n",
    "                       epochs = 10, ##number of epochs (passes through the data)\n",
    "                       batch_size = 128, ##batch size\n",
    "                       validation_split = 0.4, ##fraction of data to be used as validation\n",
    "                       shuffle = True, ##shuffle data after each epoch\n",
    "                        callbacks=[keras.callbacks.ModelCheckpoint(\n",
    "                            filepath='multi_weights_V80K_WL300.h5',\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=True,\n",
    "                            verbose=1)]\n",
    "                       );\n",
    "etime = time.time();\n",
    "print('Total time: '+str(etime-stime));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[15,8]);\n",
    "plt.plot(lstm_history.history['acc'],'-ro',linewidth=2,label='LSTM Train');\n",
    "\n",
    "plt.plot(lstm_history.history['val_acc'],':ro',linewidth=2,label='LSTM Test');\n",
    "\n",
    "plt.xlabel('Epoch');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(df_yelp['text'][1000000:1200000])\n",
    "test_data = pad_sequences(test_sequences, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_Y = np.array(df_yelp['review_rating'][1000000:1200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = lstm_model.predict_classes(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_Y,predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(test_Y,predicted_classes)\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"12345\"],\n",
    "                  columns = [i for i in \"12345\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
